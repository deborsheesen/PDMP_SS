{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_clustering_vec_and_score (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions, TimeIt, PyPlot, NPZ\n",
    "include(\"zz_structures.jl\")\n",
    "include(\"mbsampler.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d, Nobs = 10, 100\n",
    "p = 5e-1\n",
    "X = sprand(d, Nobs, p);\n",
    "y = rand(Binomial(1,0.5),Nobs);\n",
    "root = rand(d);\n",
    "\n",
    "my_ll = ll_logistic_sp(X,y);\n",
    "my_prior = gaussian_prior_nh(zeros(d),1*ones(d))\n",
    "my_model = model(my_ll, my_prior);\n",
    "root = find_root(my_model, rand(d));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_het = spzeros(d, Nobs)\n",
    "for i in 1:d \n",
    "    nzind = X[i,:].nzind\n",
    "    weights_het[i,nzind] = abs.(X[i,nzind])./sum(abs.(X[i,nzind]))\n",
    "end\n",
    "mb_size = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find root:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "npzwrite(\"root.npz\",root)\n",
    "npzwrite(\"X.npz\",X)\n",
    "npzwrite(\"y.npz\",y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Sub-sampling with weights \n",
    "gs = [wumbsampler(Nobs, mb_size, weights[i,:]) for i in 1:d]\n",
    "gs_list = mbsampler_list(d,gs);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sub-Sampling with control variate (and weights)\n",
    "mbs = [wumbsampler(Nobs, mb_size, weights_cv[i,:]) for i in 1:d];\n",
    "gs_list = cvmbsampler_list(my_model, mbs, root);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Grouped subsampling with weights \n",
    "tol = .00001\n",
    "gs = Array{mbsampler}(d)\n",
    "N_groups = 20\n",
    "mod_weights = copy(weights)\n",
    "for i in 1:d\n",
    "    grouping = Array{Int}(Nobs)\n",
    "    gclusters, gscores = get_clustering_vec_and_score(weights[i,:], N_groups, \"wc\") \n",
    "                                          # use clustering algorithm on weights\n",
    "    for (gi,gcluster) in enumerate(gclusters)\n",
    "        value = gscores[gi]/mean(weights[i,gcluster]) \n",
    "        if value < tol # If weights are very similar use uniform sub sampling\n",
    "            grouping[gcluster] = 1\n",
    "            mod_weights[i,gcluster] = mean(weights[i,gcluster]) \n",
    "        else # Otherwise use weighted sub sampling\n",
    "            grouping[gcluster] = -1\n",
    "        end\n",
    "    end\n",
    "    gs[i] = gmbsampler(mb_size,mod_weights[i,:],grouping)\n",
    "end\n",
    "gs_list = mbsampler_list(d,gs);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "weights = weights_het\n",
    "ll_pd_root_list = [sparse(partial_derivative_vec(my_model.ll, root, i, 1:Nobs)) for i in 1:d];\n",
    "\n",
    "cmbsamplers = Array{cmbsampler}(d)\n",
    "N_cluster = mb_size\n",
    "mode = \"wc\"\n",
    "\n",
    "for dim in 1:d\n",
    "    csamplers = Array{mbsampler}(N_cluster)\n",
    "    clusters = get_clustering_vec(ll_pd_root_list[dim], N_cluster, mode)\n",
    "    #print(clusters)\n",
    "    scp = ones(N_cluster)\n",
    "    for (ci, c) in enumerate(clusters)\n",
    "        #csamplers[ci] = umbsampler(size(c)[1], scp[ci])\n",
    "        csamplers[ci] = wumbsampler(size(c)[1], scp[ci], weights[dim,c])\n",
    "    end\n",
    "    #cmbsamplers[dim] = cmbsampler(csamplers, clusters, ones(Nobs)/Nobs)\n",
    "    cmbsamplers[dim] = cmbsampler(csamplers, clusters, weights[dim,:])\n",
    "end\n",
    "gs_list = mbsampler_list(d,cmbsamplers);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Stratified sub-sampling with CV (and weights)\n",
    "ξ_0 = rand(Normal(),d)\n",
    "root = find_root(my_model, ξ_0)\n",
    "ll_pd_root_list = [partial_derivative_vec(my_model.ll, root, i, 1:Nobs) for i in 1:d]\n",
    "\n",
    "cmbsamplers = Array{cmbsampler}(d)\n",
    "N_cluster = mb_size\n",
    "mode = \"wc\"\n",
    "\n",
    "for dim in 1:d\n",
    "    csamplers = Array{mbsampler}(N_cluster)\n",
    "    clusters = get_clustering_vec(ll_pd_root_list[dim], N_cluster, mode)\n",
    "    #print(clusters)\n",
    "    scp = ones(N_cluster)\n",
    "    for (ci, c) in enumerate(clusters)\n",
    "        #csamplers[ci] = umbsampler(size(c)[1], scp[ci])\n",
    "        csamplers[ci] = wumbsampler(size(c)[1], scp[ci], weights_cv[dim,c])\n",
    "    end\n",
    "    #cmbsamplers[dim] = cmbsampler(csamplers, clusters, ones(Nobs)/Nobs)\n",
    "    cmbsamplers[dim] = cmbsampler(csamplers, clusters, weights_cv[dim,:])\n",
    "end\n",
    "gs_list = cvmbsampler_list(my_model,cmbsamplers, root);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = eye(d)\n",
    "mb_size = 100\n",
    "opf = projopf(A, 100) \n",
    "opt = maxa_opt(10^5)\n",
    "outp = outputscheduler(opf,opt) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11 minutes to run \n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "ZZ_sample(my_model, outp, gs_list)\n",
    "print( round((time()-start)/60, 2), \" minutes to run \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.53 ms per loop\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10^4\n",
    "@timeit samples = extract_samples(outp.opf.xi_skeleton, outp.opf.bt_skeleton, outp.opf.bt_skeleton[end]/n_samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 55307.2      \n",
       "    -0.0825742"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[compute_configT(my_model, samples, k) for k in 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
